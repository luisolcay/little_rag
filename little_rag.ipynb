{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ab0058",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "\n",
    "#### Step 0: Set environment\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d839f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f107a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "FOLDER_PATH = os.getenv('FOLDER_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32b764",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "\n",
    "#### Step 1: Split text, create/embed chunks and load chunks\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfe5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olcay\\LuisOlcay20\\python\\IA\\RAG\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488f1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 documents loaded\n",
      "1261 chunks in total\n"
     ]
    }
   ],
   "source": [
    "#variable to split text\n",
    "from numpy.core.defchararray import endswith\n",
    "\n",
    "\n",
    "split_text = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "#function to load_documents\n",
    "def load_documents(FOLDER_PATH):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(FOLDER_PATH):\n",
    "        file_path = os.path.join(FOLDER_PATH,file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        else:\n",
    "            print(f\"The document {file_name} is not supported\")\n",
    "        \n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "#load documents\n",
    "documents = load_documents(FOLDER_PATH)\n",
    "print(f\"{len(documents)} documents loaded\")\n",
    "\n",
    "#split text of the documents\n",
    "chunks = split_text.split_documents(documents)\n",
    "print(f\"{len(chunks)} chunks in total\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e63b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call embedding model from openai\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82302595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_db = Chroma().from_documents(collection_name='collahuasi_pdfs',documents=chunks,embedding=embeddings, persist_directory='./cllh_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a05473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create retriever\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8ef4a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "#### Step 2: Start to create the chain\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e690bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call to model\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "028cdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple parse answer of the model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser =  StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6e6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template = \"\"\"\n",
    "You are an expert in environmental consulting projects in the north of Chile. \n",
    "Always answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f3be3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "#### ⚙️ Step-by-step flow of the `rag_chain`\n",
    "\n",
    "1. **Input**  \n",
    "   `\"tell me the height of the Collahuasi campament\"`\n",
    "\n",
    "2. **Branch mapping**  \n",
    "   - **context** → input goes to the `retriever`, which returns `docs`.  \n",
    "     The lambda joins all document texts into one string using `\"\\n\\n\"`.  \n",
    "   - **question** → `RunnablePassthrough()` passes the original input unchanged.\n",
    "\n",
    "3. **Prompt**  \n",
    "   The `prompt` fills its template with `{context}` and `{question}`.\n",
    "\n",
    "4. **LLM**  \n",
    "   The `llm` generates an answer based on the formatted prompt.\n",
    "\n",
    "5. **Parser**  \n",
    "   The `parser` formats or extracts the model’s output (e.g., plain text or JSON).\n",
    "\n",
    "**Result:**  \n",
    "A final, parsed answer based on the retrieved context and user question.\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3035b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# retrievers output  its docs = []\n",
    "rag_chain = (\n",
    "    {\n",
    "            \"context\":retriever | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])), \n",
    "            \"question\": RunnablePassthrough() } \n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser \n",
    ")\n",
    "\n",
    "#rag_chain.invoke('tell me the height of the collahuasi campament')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058581b",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "#### Step 3 ⚙️ Add history-aware to the chat: improve the retriever by using chat history\n",
    "\n",
    "1. **Input**  \n",
    "   User asks a question.\n",
    "\n",
    "2. **History retriever**  \n",
    "   Reformulates the question using `chat_history`, queries the retriever, and returns relevant docs.\n",
    "\n",
    "3. **Context branch**  \n",
    "   Joins all `page_content` from docs with `\"\\n\\n\"` → becomes `{context}`.\n",
    "\n",
    "4. **Prompt**  \n",
    "   Combines `{chat_history}`, `{context}`, and `{question}` into the `answer_prompt`.\n",
    "\n",
    "\n",
    "**Result:**  \n",
    "A context-aware answer built from retrieved documents and chat history.\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a768ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Base Message\n",
    "chat_history: list = []\n",
    "\n",
    "question = 'tell me the height of the collahuasi campament'\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "# Update history\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=question),\n",
    "    AIMessage(content=answer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c8bceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "contextualize_history_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Given the chat history and the latest user question, rewrite it self-contained.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "history_retriever = create_history_aware_retriever(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    prompt=contextualize_history_prompt\n",
    ")\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Use the provided context to answer the question. \"\n",
    "    \"If the answer is not present, say you don't know.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"system\", \"Context:\\n{context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "context_branch = (\n",
    "    {\n",
    "        \"input\": RunnablePassthrough(),          \n",
    "        \"chat_history\": lambda _: chat_history    \n",
    "    }\n",
    "    | history_retriever                           #history_retriever use get.\n",
    "    | (lambda docs: \"\\n\\n\".join(d.page_content for d in docs))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1dbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\":  context_branch,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"chat_history\": lambda _: chat_history, \n",
    "    }\n",
    "    | answer_prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af105f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context refers to the Collahuasi mining project, which is located in the altiplano of the Atacama Desert.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('of which project are we talking about')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95a1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'of which project are we talking about',\n",
       " 'chat_history': [HumanMessage(content='tell me the height of the collahuasi campament', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The height of the Collahuasi camp is 4,400 meters above sea level (msnm).', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='6057b28f-93cd-416b-a9d8-c3d1999685c0', metadata={'comments': '', 'moddate': '2025-03-26T15:04:12-03:00', 'subject': '', 'author': 'Fernanda Muñoz', 'page': 5, 'title': '', 'source': 'c:\\\\Users\\\\olcay\\\\LuisOlcay20\\\\python\\\\IA\\\\RAG\\\\PDFs\\\\7343-Apendice Bases Técnicas Mitigación_lic_2025VF.pdf', 'page_label': '6', 'creationdate': '2025-03-26T15:03:51-03:00', 'keywords': '', 'creator': 'Acrobat PDFMaker 20 para Word', 'producer': 'Adobe PDF Library 20.5.43', 'sourcemodified': '', 'company': 'Microsoft', 'total_pages': 33}, page_content='integrante de un equipo en una Compañía de vanguardia. \\n2.2 UBICACIÓN \\nLos yacimientos de Collahuasi se emplazan en el altiplano del desierto de Atacama, a 4.400 msnm, una \\nzona andina que se caracteriza por tener un clima lluvioso en verano y nevadas ocasionales en invierno.  \\nA 40 km de las operaciones de la mina se ubica el poblado de Huatacondo, y a 130 y 135 km las localidades \\nde Pica y Matilla respectivamente, las que están rodeadas de zonas de alto valor por su diversidad'),\n",
       "  Document(id='3d30905e-b843-460e-b316-f7e45da9e370', metadata={'subject': '', 'producer': 'Adobe PDF Library 20.5.43', 'moddate': '2025-03-26T15:04:12-03:00', 'title': '', 'creator': 'Acrobat PDFMaker 20 para Word', 'page': 5, 'sourcemodified': '', 'source': 'c:\\\\\\\\Users\\\\\\\\olcay\\\\\\\\LuisOlcay20\\\\\\\\python\\\\\\\\IA\\\\\\\\RAG\\\\\\\\PDFs\\\\7343-Apendice Bases Técnicas Mitigación_lic_2025VF.pdf', 'total_pages': 33, 'comments': '', 'creationdate': '2025-03-26T15:03:51-03:00', 'page_label': '6', 'keywords': '', 'author': 'Fernanda Muñoz', 'company': 'Microsoft'}, page_content='integrante de un equipo en una Compañía de vanguardia. \\n2.2 UBICACIÓN \\nLos yacimientos de Collahuasi se emplazan en el altiplano del desierto de Atacama, a 4.400 msnm, una \\nzona andina que se caracteriza por tener un clima lluvioso en verano y nevadas ocasionales en invierno.  \\nA 40 km de las operaciones de la mina se ubica el poblado de Huatacondo, y a 130 y 135 km las localidades \\nde Pica y Matilla respectivamente, las que están rodeadas de zonas de alto valor por su diversidad'),\n",
       "  Document(id='7f89ee87-99f0-48cf-93a2-c8782ed5e94d', metadata={'author': 'Fernanda Muñoz', 'company': 'Microsoft', 'page': 5, 'moddate': '2025-03-26T15:05:49-03:00', 'total_pages': 62, 'title': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 20 para Word', 'page_label': '6', 'source': 'c:\\\\\\\\Users\\\\\\\\olcay\\\\\\\\LuisOlcay20\\\\\\\\python\\\\\\\\IA\\\\\\\\RAG\\\\\\\\PDFs\\\\7343- Apendice Bases Técnicas Compensación_lic_2025VF.pdf', 'producer': 'Adobe PDF Library 20.5.43', 'subject': '', 'creationdate': '2025-03-26T15:05:31-03:00', 'sourcemodified': ''}, page_content='transmita a todos los niveles de su organización estableciendo un ambiente de trabajo uniforme y ser \\nintegrante de un equipo en una Compañía de vanguardia. \\nUBICACIÓN \\nLos yacimientos de Collahuasi se emplazan en el altiplano del desierto de Atacama, a 4.400 msnm, una \\nzona andina que se caracteriza por tener un clima lluvioso en verano y nevadas ocasionales en invierno. \\nA 40 km de las operaciones de la mina se ubica el poblado de Huatacondo, y a 130 y 135 km las localidades')],\n",
       " 'answer': 'We are talking about the Collahuasi mining project, which is located in the high plateau of the Atacama Desert in Chile.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''\n",
    "#another way to simplify the final part of the chain by usin prebuild chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are an environmental professional expert with specialization in Chile environment. '\n",
    "    'Use the following context to answer the users question'), \n",
    "    ('system','Context: {context}' ),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human','{input}')\n",
    "])\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain_two = create_retrieval_chain(history_retriever,qa_chain)\n",
    "rag_chain_two.invoke({'input':'of which project are we talking about','chat_history':chat_history})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fb0f7",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "#### ⚙️ Step 4 — Add persistent chat memory with SQLite\n",
    "\n",
    "1. **Database initialization**  \n",
    "   The function `app_logs()` creates a local SQLite file `little_rag_app.db` and ensures the table `app_logs` exists.  \n",
    "   Each row logs: `session_id`, `user_query`, `gpt_response`, `model`, and a timestamp.\n",
    "\n",
    "2. **Insert chat records**  \n",
    "   Every message–response pair is saved using `insert_app_logs()`, allowing each user session to have its own record.\n",
    "\n",
    "3. **Retrieve conversation history**  \n",
    "   `get_chat_history(session_id)` loads all previous messages from the same session in chronological order as  \n",
    "   `[{role: \"human\", content: ...}, {role: \"ai\", content: ...}]`.\n",
    "\n",
    "4. **Session handling**  \n",
    "   A new `session_id` is generated with `uuid.uuid4()` for each user, enabling multi-user persistence and context continuity.\n",
    "\n",
    "5. **Integration with RAG**  \n",
    "   The retrieved history is passed to `history_retriever` and `rag_chain` so the assistant maintains memory across interactions.\n",
    "\n",
    "**Result:**  \n",
    "A lightweight local database providing persistent, multi-session conversational memory for your RAG application.\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77f7b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "DB_NAME = 'little_rag_app.db'\n",
    "\n",
    "def db_connection():\n",
    "    connect = sqlite3.connect(DB_NAME)\n",
    "    connect.row_factory = sqlite3.Row\n",
    "    return connect\n",
    "\n",
    "def app_logs():\n",
    "    connect = db_connection()\n",
    "    connect.execute(\n",
    "        '''\n",
    "        CREATE TABLE IF NOT EXISTS app_logs\n",
    "            (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "             session_id TEXT,\n",
    "             user_query TEXT,\n",
    "              gpt_response TEXT,\n",
    "              model TEXT,\n",
    "               created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)\n",
    "        '''\n",
    "        )\n",
    "    connect.close()\n",
    "\n",
    "def insert_app_logs(session_id, user_query, gpt_response, model):\n",
    "    connect = db_connection()\n",
    "    connect.execute(''' \n",
    "        INSERT INTO app_logs (session_id, user_query, gpt_response, model) \n",
    "                    VALUES (?,?,?,?)\n",
    "        ''',\n",
    "        (session_id, user_query, gpt_response, model)\n",
    "        )\n",
    "    connect.commit()\n",
    "    connect.close()\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    connect = db_connection()\n",
    "    cursor = connect.cursor()\n",
    "    cursor.execute(\n",
    "        '''\n",
    "        SELECT \n",
    "            user_query,\n",
    "            gpt_response\n",
    "        FROM\n",
    "            app_logs\n",
    "        WHERE\n",
    "            session_id = ?\n",
    "        ORDER BY  created_at\n",
    "    ''',\n",
    "    (session_id,)\n",
    "    )\n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.extend([\n",
    "            {'role':'human', 'content': row['user_query']},\n",
    "            {'role':'ai', 'content': row['gpt_response']}\n",
    "\n",
    "        ]) \n",
    "    connect.close()\n",
    "    return messages\n",
    "\n",
    "# Start db\n",
    "\n",
    "app_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f801ef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Human: tell me the height of the collahuasi campament\n",
      "AI: The height of the Collahuasi camp is 4,400 meters above sea level (msnm).\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "session_id = str(uuid.uuid4())\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "\n",
    "insert_app_logs(session_id, question,answer,'gpt-4o')\n",
    "print(f'Human: {question}')\n",
    "print(f'AI: {answer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
