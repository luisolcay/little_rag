{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ab0058",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "\n",
    "#### Step 0: Set environment\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d839f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olcay\\LuisOlcay20\\python\\IA\\RAG\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f107a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "FOLDER_PATH = os.getenv('FOLDER_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32b764",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "\n",
    "#### Step 1: Split text, create/embed chunks and load chunks\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adfe5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488f1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 documents loaded\n",
      "1261 chunks in total\n"
     ]
    }
   ],
   "source": [
    "#variable to split text\n",
    "from numpy.core.defchararray import endswith\n",
    "\n",
    "\n",
    "split_text = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "#function to load_documents\n",
    "def load_documents(FOLDER_PATH):\n",
    "    documents = []\n",
    "    for file_name in os.listdir(FOLDER_PATH):\n",
    "        file_path = os.path.join(FOLDER_PATH,file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        else:\n",
    "            print(f\"The document {file_name} is not supported\")\n",
    "        \n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "#load documents\n",
    "documents = load_documents(FOLDER_PATH)\n",
    "print(f\"{len(documents)} documents loaded\")\n",
    "\n",
    "#split text of the documents\n",
    "chunks = split_text.split_documents(documents)\n",
    "print(f\"{len(chunks)} chunks in total\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e63b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call embedding model from openai\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82302595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_db = Chroma().from_documents(collection_name='collahuasi_pdfs',documents=chunks,embedding=embeddings, persist_directory='./cllh_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a05473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create retriever\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8ef4a",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "#### Step 2: Start to create the chain\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e690bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call to model\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028cdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple parse answer of the model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser =  StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6e6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template = \"\"\"\n",
    "You are an expert in environmental consulting projects in the north of Chile. \n",
    "Always answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f3be3",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "### ⚙️ Step-by-step flow of the `rag_chain`\n",
    "\n",
    "1. **Input**  \n",
    "   `\"tell me the height of the Collahuasi campament\"`\n",
    "\n",
    "2. **Branch mapping**  \n",
    "   - **context** → input goes to the `retriever`, which returns `docs`.  \n",
    "     The lambda joins all document texts into one string using `\"\\n\\n\"`.  \n",
    "   - **question** → `RunnablePassthrough()` passes the original input unchanged.\n",
    "\n",
    "3. **Prompt**  \n",
    "   The `prompt` fills its template with `{context}` and `{question}`.\n",
    "\n",
    "4. **LLM**  \n",
    "   The `llm` generates an answer based on the formatted prompt.\n",
    "\n",
    "5. **Parser**  \n",
    "   The `parser` formats or extracts the model’s output (e.g., plain text or JSON).\n",
    "\n",
    "**Result:**  \n",
    "A final, parsed answer based on the retrieved context and user question.\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3035b39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Collahuasi campament is located at an altitude of 4,400 meters above sea level.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# retrievers output  its docs = []\n",
    "rag_chain = (\n",
    "    {\n",
    "            \"context\":retriever | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])), \n",
    "            \"question\": RunnablePassthrough() } \n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser \n",
    ")\n",
    "\n",
    "rag_chain.invoke('tell me the height of the collahuasi campament')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
